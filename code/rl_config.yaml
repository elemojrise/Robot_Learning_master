seed: 0
training: True   # Whether to train a model or not

# Settings for stable-baselines RL algorithm
sb_config:
  total_timesteps: 40.0e+6
  num_procs: 12

# Policy settings
sb_policy:
  type: "MultiInputPolicy"
  learning_rate: 0.0003 
  n_steps: 1024 
  batch_size: 64 
  n_epochs: 10 
  gamma: 0.99 
  gae_lambda: 0.95 
  clip_range: 0.2 
  clip_range_vf: null 
  ent_coef: 0.0 
  vf_coef: 0.5 
  max_grad_norm: 0.5
  use_sde: False 
  sde_sample_freq: -1 
  target_kl: null 
  create_eval_env: False 
  policy_kwargs: null
  verbose: 1 
  seed: null
  device: 'auto' 
  _init_setup_model: True
  # net_arch: 
  #   - pi: [256, 128]    # Custom actor network
  #     vf: [256, 128]    # Value function network

# Specify environment
robosuite:
  env_id: "Lift_edit"
  robots: "IIWA_14"
  gripper_types: "Robotiq85Gripper_iiwa_14"      
  has_renderer: False                    
  has_offscreen_renderer: True           
  control_freq: 20                       
  horizon: 400
  camera_heights: 300                          
  use_object_obs: False                  
  use_camera_obs: True
  reward_shaping: True
  camera_names: "custom"
  custom_camera_name: "custom" 
  custom_camera_trans_matrix: [ [ 0.011358,  0.433358, -0.901150,  1220.739746], 
                                [ 0.961834,  0.241668,  0.128340, -129.767868], 
                                [ 0.273397, -0.868215, -0.414073,  503.424103], 
                                [ 0.000000,  0.000000,  0.000000,  1.000000] ]
  custom_camera_conversion: True
  custom_camera_attrib:  {"fovy": 36}
  controller_configs: 
    type: "OSC_POSE"
    input_max: 1
    input_min: -1
    output_max: [0.05, 0.05, 0.05, 0.5, 0.5, 0.5]
    output_min: [-0.05, -0.05, -0.05, -0.5, -0.5, -0.5]
    kp: 150
    damping_ratio: 1
    impedance_mode: "fixed"
    kp_limits: [0, 300]
    damping_ratio_limits: [0, 10]
    position_limits": null
    orientation_limits: null
    uncouple_pos_ori: true
    control_delta: true
    interpolation: null
    ramp_ratio: 0.2
  
wandb_callback:
  gradient_save_freq: 10000
  verbose: 2

eval_callback:
  callback_on_new_best: null
  n_eval_episodes: 10
  eval_freq: 2048 
  log_path: './logs_real_smaller_action_space/' 
  best_model_save_path: './logs_real_smaller_action_space/'
  deterministic: true
  render: False 
  verbose: 1 
  warn: True

gymwrapper:
  observations: ["custom_image"]
  smaller_action_space: true

wandb:
  project: "sb3_lift_real"
  sync_tensorboard: True 
  save_code: True


# Settings used for file handling and logging (save/load destination etc)
file_handling:
  # Path to model which should be continued to train
  continue_training_model_folder: "logs_real_smaller_action_space"
  continue_training_model_filename: "best_model" # is null when training a new model
